# z3-Agent RAG Configuration
# Research-validated optimal settings from agentic-rag Phase 9A
#
# Results: 0.828 precision (exceeds 0.80 target)
# Domain: E-commerce Customer Service (TokoPedia)
# Date: 2025-11-21

# Embedding Model Configuration
# MPNet provides better semantic understanding than MiniLM
# Model size: ~500MB, Embedding dim: 768
embedding_model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2

# Document Chunking Configuration
# Optimal for e-commerce CS domain (tested in Phase 6)
# Smaller chunks = better granularity for retrieval
chunk_size: 500
chunk_overlap: 50

# Retrieval Configuration
# Retrieve 7 candidates, then rerank to top-3
# k=7 provides good candidate pool for reranker
retrieval_k: 7

# Reranker Configuration (Phase 9A: +5.7% precision improvement)
# BGE cross-encoder provides semantic relevance scoring
use_reranker: true
reranker_model: BAAI/bge-reranker-base
reranker_top_k: 3
reranker_use_fp16: true  # Half precision for faster inference

# Relevance Threshold
# When use_reranker=true: BGE score threshold (-10 to +10 range)
# When use_reranker=false: Word overlap threshold (0 to 1 range)
# Research shows threshold=1.0 maintains quality while improving efficiency
relevance_threshold: 1.0

# Adaptive Fallback Logic
# If no chunks pass threshold, use top chunks based on score
# Prevents returning empty results
enable_adaptive_fallback: true
